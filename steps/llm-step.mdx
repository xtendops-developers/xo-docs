---
title: LLM Step
description: Generate AI-driven responses using large language models
icon: "sparkles"
---

The **LLM Step** uses prompts to generate AI-driven responses using large language models.

## Overview

The LLM Step is the core AI component in most SmartAgent workflows. It generates human-like responses to customer inquiries using advanced language models with customizable prompts.

<div align="center">![LLM Step](/images/steps/llm-step.png)</div>

## Settings

### LLM and Model

Select the LLM provider and specific model for this step. Overrides the default LLM and model set in SmartAgent settings. Higher-tier models provide better reasoning but cost more and run slower.

### Prompt

The prompt sent to the LLM to generate a response. Supports dynamic variables from previous steps or conversation context.

**Dynamic variables:**

- `{original_question}` - Last customer message
- `{chat_history}` - Full conversation thread
- `{user_first_name}` - Customer's first name
- `{user_last_name}` - Customer's last name
- `{steps_last_performed}` - Complete string of all steps ran in the previous message
- `{conversation_last_step}` - Final step performed in the previous message
- Any custom background variables

**Example:**

```
You are a helpful customer service agent.

Customer question: {customer_message}

Relevant knowledge: {knowledge_search.results}

Provide a clear, professional response.
```

## Outputs

### Outputs

Name of the variable where the LLM response will be saved. This can be referenced in subsequent steps using `{variable_name}`.

**Default:** `response`

### Next Steps

The step(s) to execute after this step completes. Select from existing steps or enter a custom step name using variables.

### Send to Copilot

When enabled, sends the output to the Copilot app for agent review before sending to the user.

### Send Automatically

When enabled, sends the output directly to the user without requiring agent intervention.

## Advanced Settings

### Follow Up Steps

Steps that run in parallel after this step completes. Use this for actions that don't need to block the workflow, such as logging or analytics.

### Background Steps

Steps that run in the background while the main workflow continues. Useful for long-running tasks that shouldn't delay the response.

### Write Outputs to Background Context

When enabled, saves the step output to the background context, making it available to all subsequent steps in the conversation without explicitly passing it.

## Related Pages

- [Q\* Step](/steps/q-star) - Self-improving AI step
- [Knowledge Search](/steps/knowledge-search) - Retrieve relevant knowledge
- [Structured Output](/steps/structured-output) - Format LLM responses
