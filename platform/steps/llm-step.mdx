---
title: LLM Step
description: Generate AI-driven responses using large language models
icon: "sparkles"
---

The **LLM Step** uses prompts to generate AI-driven responses using large language models.

## Overview

The LLM Step is the core AI component in most SmartAgent workflows. It generates human-like responses to customer inquiries using advanced language models with customizable prompts.

## Settings

### LLM

Select the LLM provider for this step. Overrides the default LLM set in SmartAgent settings.

**Options:**
- OpenAI
- Anthropic
- Azure
- Google (Gemini)
- And more

### LLM Model

Choose the specific model to use with the selected provider.

**Common models:**
- GPT-4o, GPT-4o-mini (OpenAI)
- Claude Sonnet, Claude Haiku (Anthropic)
- Gemini Pro, Gemini Flash (Google)

Higher-tier models provide better reasoning but cost more and run slower.

### Prompt

The prompt sent to the LLM to generate a response. Supports dynamic variables from previous steps or conversation context.

**Dynamic variables:**
- `{customer_message}` - Latest customer input
- `{conversation_history}` - Full conversation thread
- `{step_name.output}` - Output from a previous step
- Any custom background variables

**Example:**
```
You are a helpful customer service agent.

Customer question: {customer_message}

Relevant knowledge: {knowledge_search.results}

Provide a clear, professional response.
```

## Outputs

### Outputs

Name of the variable where the LLM response will be saved. This can be referenced in subsequent steps using `{variable_name}`.

**Default:** `response`

### Next Steps

The step(s) to execute after this step completes. Select from existing steps or enter a custom step name using variables.

### Send to Copilot

When enabled, sends the output to the Copilot app for agent review before sending to the user.

### Send Automatically

When enabled, sends the output directly to the user without requiring confirmation.

## Advanced Settings

### Follow Up Steps

Steps that run in parallel after this step completes. Use this for actions that don't need to block the workflow, such as logging or analytics.

### Background Steps

Steps that run in the background while the main workflow continues. Useful for long-running tasks that shouldn't delay the response.

### Write Outputs to Background Context

When enabled, saves the step output to the background context, making it available to all subsequent steps in the conversation without explicitly passing it.

## Related Pages

- [Q* Step](/platform/steps/q-star) - Self-improving AI step
- [Knowledge Search](/platform/steps/knowledge-search) - Retrieve relevant knowledge
- [Structured Output](/platform/steps/structured-output) - Format LLM responses
