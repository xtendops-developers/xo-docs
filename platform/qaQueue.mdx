---
title: Quality
description: Tools for collecting and reviewing SmartAgent feedback
icon: "clipboard-check"
---

The **Quality** section provides tools for collecting and reviewing feedback on SmartAgent performance. It consists of three main tabs that enable systematic quality assessment and continuous improvement.

## Overview

Quality management is essential for maintaining high standards in AI-generated responses. This section provides the infrastructure to review conversations, collect feedback, and track performance over time.

<img
  src="/images/screenshots/quality-queue-interface.png"
  alt="Quality Queue Interface"
/>

## Tabs

### Queue

A workspace for reviewing items flagged for quality assessment. Items can be automatically or manually added for review.

**What's in the Queue:**

#### Messages

Individual messages with their complete context:

- Customer input
- AI-generated response
- Final delivered message
- Background context

#### Conversations

Full conversation threads for context-rich feedback, allowing reviewers to:

- See the complete customer journey
- Assess multi-turn interactions
- Evaluate conversation flow
- Identify patterns

#### QA Rules

Outputs from QA SmartAgents that have graded conversations and sent results to the queue for human review.

**Feedback Collection:**

- **Thumbs Up/Down** - Binary quality assessment
- **Reason** - Categorized reason for the rating
- **Comment** - Optional detailed feedback

**Integration:**

- Results are integrated into the BI platform for reporting
- Used to ensure confidence in AI performance
- Informs prompt/step improvements
- Tracks quality trends over time

### Conversations

Allows review of raw conversation data within a client account.

**Features:**

- Displays complete back-and-forth between user and AI
- Enables performance assessment
- Provides feedback interface
- Filterable by date, SmartAgent, and tags

**Use Cases:**

- Random quality sampling
- Investigating specific issues
- Training and calibration
- Customer escalations review

### Rules

Used to create automated QA rules that run on a schedule.

**Capabilities:**

- Select random sampling of conversations or messages each day
- Populate the queue automatically for review
- Provide random performance datasets for analysis
- Enable quality insights sharing with customers

**Configuration Options:**

- **Schedule** - Daily, weekly, or custom frequency
- **Sample Size** - Number of items to select
- **Filters** - SmartAgent, date range, tags
- **Assignment** - Which reviewers see which items

## Purpose

The Quality section enables performance validation by ensuring AI responses meet quality standards and tracking metrics over time. It supports continuous improvement through structured feedback collection that informs prompt engineering and guides SmartAgent modifications. The data provides customer transparency by demonstrating satisfaction levels and building confidence in AI performance, while also serving as risk mitigation to catch problematic responses early and prevent recurring issues.

## Workflow and Best Practices

1. **Items Enter Queue** - Automatically via rules or manually flagged
2. **Regular Review** - Schedule consistent review sessions with calibrated reviewers
3. **Reviewers Assess** - Evaluate messages/conversations and provide specific, actionable feedback
4. **Random Sampling** - Review both flagged items and random samples for balanced assessment
5. **Feedback Collected** - Thumbs up/down, reason, and detailed comments captured
6. **Track Trends** - Monitor quality metrics over time via BI platform integration
7. **Close the Loop** - Use insights to drive improvements to SmartAgents

## Related Pages

- [Testing Suite](/platform/evals) - Automated testing and benchmarking
- [SmartAgent Builder](/platform/smartAgentBuilder) - Make improvements based on feedback
- [Reporting](/platform/reporting) - Analyze quality trends
